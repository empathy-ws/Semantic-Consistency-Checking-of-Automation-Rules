{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"uWsNJPzmQJ26"},"source":["# A BERT-based Model for Semantic Consistency Checking of Automation Rules\n","\n","**Authors:** \n","<br>[Bernardo Breve](https://orcid.org/0000-0002-3898-7512)<br>\n","[Gaetano Cimino](https://orcid.org/0000-0001-8061-7104)<br>\n","[Vincenzo Deufemia](https://orcid.org/0000-0002-6711-3590)<br>\n","[Annunziata Elefante](https://orcid.org/0009-0001-7141-6105)<br>\n","**Date created:** 2023/04/24<br>\n","**Description:** In this paper, we propose a BERT (Bidirectional Encoder Representations from Transformers)-based model for semantic consistency checking of IFTTT applets. Our model uses pre-trained language representations to learn the semantics of applet components and identifies inconsistencies within the user-defined descriptions associated with applets."]},{"cell_type":"markdown","metadata":{"id":"_pISSCfUQJ29"},"source":["## Introduction\n","\n","According to the IFTTT creation paradigm, when a user creates\n","a new applet, the creator must specify a natural language description that summarize how the applet works. By reading this field, a new user can more easily understand what an applet is for and decide whether or not to activate it on their device. However, on the part of IFTTT, there is no control over\n","the content of the description entered by the user, so the creator could write anything, falsely describing the appletâ€™s behavior. To this end, we developed a model that can check whether there is some semantic consistency between the trigger-action components of an applet and its natural language description provided by its creator. We fine-tuned a BERT-based classification model that takes as input a pattern derived from the applet components and the corresponding user-defined description and outputs a label ('entailment' or 'contradiction') and a similarity score for these two sentences. \n","\n","### References\n","\n","* [\"An empirical characterization of IFTTT: ecosystem, usage, and performance\"](https://doi.org/10.1145/3131365.3131369)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wbBjPCDhUe_v"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"erq0DsZgnwuP"},"outputs":[],"source":["!pip install nltk"]},{"cell_type":"markdown","metadata":{"id":"Y3_tLufEQJ2-"},"source":["## Setup\n","\n","Note: install HuggingFace `transformers` via `pip install transformers` (version >= 2.11.0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import transformers\n","import pandas as pd\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","import seaborn as sn\n","import matplotlib.pyplot as plt\n","import sklearn.metrics as metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bGvpnuXzG4Pq"},"outputs":[],"source":["\n","train_path = 'semantic_training_set.csv'\n","\n","col_names = ['similarity','pattern','desc']\n","train_df = pd.read_csv(train_path,skiprows=1,sep=';',names=col_names,encoding = \"ISO-8859-1\")\n","\n","train_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G2cXoLSpHnx-"},"outputs":[],"source":["val_path = 'semantic_validation_set.csv'\n","\n","valid_df = pd.read_csv(val_path,skiprows=1,sep=';',names=col_names,encoding = \"ISO-8859-1\")\n","\n","valid_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNfTve2NITiC"},"outputs":[],"source":["test_path = 'semantic_test_set.csv'\n","\n","test_df = pd.read_csv(test_path,skiprows=1,sep=';',names=col_names,encoding = \"ISO-8859-1\")\n","\n","test_df"]},{"cell_type":"markdown","metadata":{"id":"G-9Ov0dnQJ3A"},"source":["## Configuration"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682329295638,"user":{"displayName":"GAETANO CIMINO","userId":"15514720190860715047"},"user_tz":-120},"id":"eubLJ_FTQJ3A"},"outputs":[],"source":["max_length = 70  # Maximum length of input sentence to the model.\n","batch_size = 32\n","epochs = 4\n","\n","# Labels in our dataset.\n","labels = [\"contradiction\", \"entailment\"]"]},{"cell_type":"markdown","metadata":{"id":"XI7rD3IlQJ3B"},"source":["## Load the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nfx0KmrnGA7e"},"outputs":[],"source":["# Shape of the data\n","print(f\"Total training samples : {train_df.shape[0]}\")\n","print(f\"Total validation samples: {valid_df.shape[0]}\")\n","print(f\"Total test samples: {test_df.shape[0]}\")"]},{"cell_type":"markdown","metadata":{"id":"m3LhadV0QJ3F"},"source":["Dataset Overview:\n","\n","- pattern: IF Any new SMS received (Android SMS) THEN Send me an email (Email).\n","- description: A mail will be sent to yourself when you receive a sms.\n","- similarity: This is the label chosen by the majority of annotators.\n","\n","The applets were labeled according to the following similarity label values:\n","\n","- Contradiction: indicates inconsistency between the description of the creator and the description synthesized.\n","- Entailment: denotes consistency between the description of the creator and the description synthesized."]},{"cell_type":"markdown","metadata":{"id":"mqWphvQYQJ3F"},"source":["Let's look at one sample from the dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZr5djjyQJ3G"},"outputs":[],"source":["print(f\"Pattern: {train_df.loc[5, 'pattern']}\")\n","print(f\"Description: {train_df.loc[5, 'desc']}\")\n","print(f\"Similarity: {train_df.loc[5, 'similarity']}\")"]},{"cell_type":"markdown","metadata":{"id":"XjmqiCXLQJ3H"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LACMJeSZQJ3H"},"outputs":[],"source":["# We have some NaN entries in our train data, we will simply drop them.\n","print(\"Number of missing values\")\n","print(train_df.isnull().sum())\n","train_df.dropna(axis=0, inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"kmaOm2QPQJ3I"},"source":["Distribution of our training, validation, and test targets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fu2xw-NNQJ3I"},"outputs":[],"source":["print(\"Training Target Distribution\")\n","print(train_df.similarity.value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TpAD3gwy4Yzm"},"outputs":[],"source":["print(\"Validation Target Distribution\")\n","print(valid_df.similarity.value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HgQuANocILxx"},"outputs":[],"source":["print(\"Test Target Distribution\")\n","print(test_df.similarity.value_counts())"]},{"cell_type":"markdown","metadata":{"id":"GIibWiAetGsT"},"source":["Removal of stop words and punctuation characters"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1682329296263,"user":{"displayName":"GAETANO CIMINO","userId":"15514720190860715047"},"user_tz":-120},"id":"BEJg-xtLMMTq"},"outputs":[],"source":["def remove_punctuations(text):\n","    for punctuation in string.punctuation:\n","        text = str(text).replace(punctuation, '')\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jxOln-7_lrEk"},"outputs":[],"source":["def remove_stop_words(text):\n","  text_tokens = word_tokenize(text)\n","  tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n","  filtered_sentence = (\" \").join(tokens_without_sw)\n","  return filtered_sentence"]},{"cell_type":"markdown","metadata":{"id":"lgYuqoNztmxz"},"source":["Text normalization"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1682329297919,"user":{"displayName":"GAETANO CIMINO","userId":"15514720190860715047"},"user_tz":-120},"id":"935iQzuSoUQi"},"outputs":[],"source":["def lowercase(text):\n","  return str(text).lower()"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":637275,"status":"ok","timestamp":1682329935191,"user":{"displayName":"GAETANO CIMINO","userId":"15514720190860715047"},"user_tz":-120},"id":"cNEP61XyKmX1"},"outputs":[],"source":["train_df[\"desc\"] = train_df[\"desc\"].apply(remove_punctuations)\n","train_df[\"desc\"] = train_df[\"desc\"].apply(remove_stop_words)\n","train_df[\"desc\"] = train_df[\"desc\"].apply(lowercase)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":18455,"status":"ok","timestamp":1682329953629,"user":{"displayName":"GAETANO CIMINO","userId":"15514720190860715047"},"user_tz":-120},"id":"B8UKC115MgaD"},"outputs":[],"source":["valid_df[\"desc\"] = valid_df[\"desc\"].apply(remove_punctuations)\n","valid_df[\"desc\"] = valid_df[\"desc\"].apply(remove_stop_words)\n","valid_df[\"desc\"] = valid_df[\"desc\"].apply(lowercase)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":39312,"status":"ok","timestamp":1682329992926,"user":{"displayName":"GAETANO CIMINO","userId":"15514720190860715047"},"user_tz":-120},"id":"CrFGxt5mIwry"},"outputs":[],"source":["test_df[\"desc\"] = test_df[\"desc\"].apply(remove_punctuations)\n","test_df[\"desc\"] = test_df[\"desc\"].apply(remove_stop_words)\n","test_df[\"desc\"] = test_df[\"desc\"].apply(lowercase)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fxtSlooGmF9V"},"outputs":[],"source":["train_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42UNs6aImGl0"},"outputs":[],"source":["valid_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D86j3AAdmHuz"},"outputs":[],"source":["test_df"]},{"cell_type":"markdown","metadata":{"id":"CplT-r7ZQJ3J"},"source":["One-hot encode training, validation, and test labels"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1682324511841,"user":{"displayName":"GAETANO CIMINO","userId":"15514720190860715047"},"user_tz":-120},"id":"vCZCbQGIQJ3J"},"outputs":[],"source":["train_df[\"label\"] = train_df[\"similarity\"].apply(lambda x: 0 if x == \"contradiction\" else 1)\n","y_train = tf.keras.utils.to_categorical(train_df.label, num_classes=2)\n","\n","valid_df[\"label\"] = valid_df[\"similarity\"].apply(lambda x: 0 if x == \"contradiction\" else 1)\n","y_val = tf.keras.utils.to_categorical(valid_df.label, num_classes=2)\n","\n","test_df[\"label\"] = test_df[\"similarity\"].apply(lambda x: 0 if x == \"contradiction\" else 1)\n","y_test = tf.keras.utils.to_categorical(test_df.label, num_classes=2)"]},{"cell_type":"markdown","metadata":{"id":"k_300DUCQJ3J"},"source":["## Keras Custom Data Generator"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":333,"status":"ok","timestamp":1682324612422,"user":{"displayName":"GAETANO CIMINO","userId":"15514720190860715047"},"user_tz":-120},"id":"HFfTzqltQJ3K"},"outputs":[],"source":["class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n","    \"\"\"Generates batches of data.\n","\n","    Args:\n","        sentence_pairs: Array of premise and hypothesis input sentences.\n","        labels: Array of labels.\n","        batch_size: Integer batch size.\n","        shuffle: boolean, whether to shuffle the data.\n","        include_targets: boolean, whether to incude the labels.\n","\n","    Returns:\n","        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n","        (or just `[input_ids, attention_mask, `token_type_ids]`\n","         if `include_targets=False`)\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        sentence_pairs,\n","        labels,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        include_targets=True,\n","    ):\n","        self.sentence_pairs = sentence_pairs\n","        self.labels = labels\n","        self.shuffle = shuffle\n","        self.batch_size = batch_size\n","        self.include_targets = include_targets\n","        # Load our BERT Tokenizer to encode the text.\n","        # We will use base-base-uncased pretrained model.\n","        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n","            \"bert-base-uncased\", do_lower_case=True\n","        )\n","        self.indexes = np.arange(len(self.sentence_pairs))\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        # Denotes the number of batches per epoch.\n","        return len(self.sentence_pairs) // self.batch_size\n","\n","    def __getitem__(self, idx):\n","        # Retrieves the batch of index.\n","        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n","        sentence_pairs = self.sentence_pairs[indexes]\n","\n","        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n","        # encoded together and separated by [SEP] token.\n","        encoded = self.tokenizer.batch_encode_plus(\n","            sentence_pairs.tolist(),\n","            add_special_tokens=True,\n","            max_length=max_length,\n","            return_attention_mask=True,\n","            return_token_type_ids=True,\n","            pad_to_max_length=True,\n","            return_tensors=\"tf\",\n","        )\n","\n","        # Convert batch of encoded features to numpy array.\n","        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n","        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n","        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n","\n","        # Set to true if data generator is used for training/validation.\n","        if self.include_targets:\n","            labels = np.array(self.labels[indexes], dtype=\"int32\")\n","            return [input_ids, attention_masks, token_type_ids], labels\n","        else:\n","            return [input_ids, attention_masks, token_type_ids]\n","\n","    def on_epoch_end(self):\n","        # Shuffle indexes after each epoch if shuffle is set to True.\n","        if self.shuffle:\n","            np.random.RandomState(42).shuffle(self.indexes)\n"]},{"cell_type":"markdown","metadata":{"id":"B3WphhYCQJ3K"},"source":["## Build the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQKK4NxoQJ3L"},"outputs":[],"source":["# Create the model under a distribution strategy scope.\n","strategy = tf.distribute.MirroredStrategy()\n","\n","with strategy.scope():\n","    # Create a new model instance\n","    input_ids = tf.keras.layers.Input(\n","    shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n","    )\n","    # Attention masks indicates to the model which tokens should be attended to.\n","    attention_masks = tf.keras.layers.Input(\n","    shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n","    )\n","    # Token type ids are binary masks identifying different sequences in the model.\n","    token_type_ids = tf.keras.layers.Input(\n","    shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n","    )\n","    # Loading pretrained BERT model.\n","    bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\n","    # Freeze the BERT model to reuse the pretrained features without modifying them.\n","    bert_model.trainable = False\n","\n","    bert_output = bert_model(\n","    input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n","    )\n","    sequence_output = bert_output.last_hidden_state\n","    pooled_output = bert_output.pooler_output\n","    # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n","    bi_lstm = tf.keras.layers.Bidirectional(\n","    tf.keras.layers.LSTM(64, return_sequences=True)\n","    )(sequence_output)\n","    # Applying hybrid pooling approach to bi_lstm sequence output.\n","    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n","    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n","    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n","    dropout = tf.keras.layers.Dropout(0.3)(concat)\n","    output = tf.keras.layers.Dense(2, activation=\"softmax\")(dropout)\n","    model = tf.keras.models.Model(\n","    inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n","    )\n","\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(),\n","        loss=\"categorical_crossentropy\",\n","        metrics=[\"acc\"],\n","    )\n","\n","\n","print(f\"Strategy: {strategy}\")\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"2IT-5ss1QJ3L"},"source":["Create train and validation data generators"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FbhNiYewQJ3L"},"outputs":[],"source":["train_data = BertSemanticDataGenerator(\n","    train_df[[\"pattern\", \"desc\"]].values.astype(\"str\"),\n","    y_train,\n","    batch_size=batch_size,\n","    shuffle=True,\n",")\n","valid_data = BertSemanticDataGenerator(\n","    valid_df[[\"pattern\", \"desc\"]].values.astype(\"str\"),\n","    y_val,\n","    batch_size=batch_size,\n","    shuffle=False,\n",")"]},{"cell_type":"markdown","metadata":{"id":"zx9y9CGfQJ3L"},"source":["## Train the Model\n","\n","The training process solely targets the top layers, enabling them to perform \"feature extraction,\" which, in turn, facilitates the utilization of the representations of the pretrained model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UCVB8Ap-QJ3M"},"outputs":[],"source":["history = model.fit(\n","    train_data,\n","    validation_data=valid_data,\n","    epochs=epochs,\n","    use_multiprocessing=True,\n","    workers=-1,\n",")"]},{"cell_type":"markdown","metadata":{"id":"XkM0pyG7QJ3M"},"source":["## Fine-tuning\n","\n","After the feature extraction model has achieved convergence on the new data, this step should be executed exclusively. The step involves unfreezing the BERT model, followed by its retraining using a considerably low learning rate. The purpose of this optional step is to progressively adapt the pretrained features to the new data, which can significantly enhance the performance of the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O8jXCmUuQJ3M"},"outputs":[],"source":["# Unfreeze the bert_model.\n","bert_model.trainable = True\n","# Recompile the model to make the change effective.\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(1e-5),\n","    loss=\"categorical_crossentropy\",\n","    metrics=[\"accuracy\"],\n",")\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"-3XbE-XOQJ3M"},"source":["# Train the entire model end-to-end"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oagZGrnWQJ3M"},"outputs":[],"source":["history = model.fit(\n","    train_data,\n","    validation_data=valid_data,\n","    epochs=epochs,\n","    use_multiprocessing=True,\n","    workers=-1,\n",")"]},{"cell_type":"markdown","metadata":{"id":"pWZHsS9iQJ3N"},"source":["## Evaluate model on the test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iih7X_ewJQdX"},"outputs":[],"source":["test_data = BertSemanticDataGenerator(\n","    test_df[[\"pattern\", \"desc\"]].values.astype(\"str\"),\n","    y_test,\n","    batch_size=batch_size,\n","    shuffle=False,\n",")\n","model.evaluate(test_data, verbose=1)"]},{"cell_type":"markdown","metadata":{"id":"IeWVm2weiJFB"},"source":["## Save model weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbP65PIPiFji"},"outputs":[],"source":["output_dir = 'path'\n","\n","# Save the weights\n","model.save_weights(output_dir)"]},{"cell_type":"markdown","metadata":{"id":"Uy9lioEtQJ3N"},"source":["## Load model weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S0jj47doIGf6"},"outputs":[],"source":["# Create a new model instance\n","input_ids = tf.keras.layers.Input(\n","shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n",")\n","# Attention masks indicates to the model which tokens should be attended to.\n","attention_masks = tf.keras.layers.Input(\n","shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n",")\n","# Token type ids are binary masks identifying different sequences in the model.\n","token_type_ids = tf.keras.layers.Input(\n","shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n",")\n","# Loading pretrained BERT model.\n","bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\n","# Freeze the BERT model to reuse the pretrained features without modifying them.\n","bert_model.trainable = False\n","\n","bert_output = bert_model(\n","input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n",")\n","sequence_output = bert_output.last_hidden_state\n","pooled_output = bert_output.pooler_output\n","# Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n","bi_lstm = tf.keras.layers.Bidirectional(\n","tf.keras.layers.LSTM(64, return_sequences=True)\n",")(sequence_output)\n","# Applying hybrid pooling approach to bi_lstm sequence output.\n","avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n","max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n","concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n","dropout = tf.keras.layers.Dropout(0.3)(concat)\n","output = tf.keras.layers.Dense(2, activation=\"softmax\")(dropout)\n","model = tf.keras.models.Model(\n","inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n",")\n","\n","# Restore the weights\n","model.load_weights(output_dir)"]},{"cell_type":"markdown","metadata":{"id":"0UmcYdmGKcHK"},"source":["## Prediction on the test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kCF4PJo_h8II"},"outputs":[],"source":["def check_similarity(sentence1, sentence2):\n","    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n","    test_data = BertSemanticDataGenerator(\n","        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n","    )\n","\n","    proba = model.predict(test_data[0])[0]\n","    idx = np.argmax(proba)\n","    proba = f\"{proba[idx]: .2f}%\"\n","    pred = labels[idx]\n","    return pred, proba"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mZyTWi1aKh6l"},"outputs":[],"source":["results = []\n","probabilities = []\n","\n","for i in range(0, len(test_df)):\n","  try: \n","    print(i)\n","    print(test_df.loc[i, 'desc'])\n","    result = check_similarity(test_df.loc[i, 'desc'], test_df.loc[i, 'pattern'])\n","    print(\"Predicted label: \", result[0])\n","    print(\"True label: \", test_df.iloc[i]['similarity'])\n","    print(result[1])\n","    results.append(result[0])\n","    probabilities.append(result[1])\n","  except:\n","    print(\"Prediction Error\")"]},{"cell_type":"code","execution_count":58,"metadata":{"executionInfo":{"elapsed":526,"status":"ok","timestamp":1682325109652,"user":{"displayName":"GAETANO CIMINO","userId":"15514720190860715047"},"user_tz":-120},"id":"m7xLzglWLVLT"},"outputs":[],"source":["test_error = pd.DataFrame({'desc': test_df['desc'], 'pattern': test_df['pattern'], 'true_label': test_df['similarity'], 'result': results, 'probability': probabilities})\n","\n","test_error.to_csv('test_semantic_results.csv')\n","!cp test_semantic_results.csv \"Results\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1088,"status":"ok","timestamp":1682325299653,"user":{"displayName":"GAETANO CIMINO","userId":"15514720190860715047"},"user_tz":-120},"id":"v4vBSvlDMEbj","outputId":"510e8adc-4197-4ca3-80e8-7d4faa097da4"},"outputs":[],"source":["data = pd.DataFrame({'prediction':test_error['result'], 'true_label':test_error['true_label']})\n","\n","# precision tp / (tp + fp)\n","precision = precision_score(data['true_label'], data['prediction'], average = 'macro')\n","print('Precision: %f' % precision)\n","# recall: tp / (tp + fn)\n","recall = recall_score(data['true_label'], data['prediction'], average = 'macro')\n","print('Recall: %f' % recall)\n","# f1: 2 tp / (2 tp + fp + fn)\n","f1 = f1_score(data['true_label'], data['prediction'], average = 'macro')\n","print('F1 score: %f' % f1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1682325302150,"user":{"displayName":"GAETANO CIMINO","userId":"15514720190860715047"},"user_tz":-120},"id":"2qeoudxhMJOR","outputId":"73700f9e-57bc-47f5-d7ba-3bf7e96e1838"},"outputs":[],"source":["print(\"Classification report for classifier:\\n%s\\n\"\n","      % (metrics.classification_report(data['true_label'], data['prediction'])))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"elapsed":556,"status":"ok","timestamp":1682325304654,"user":{"displayName":"GAETANO CIMINO","userId":"15514720190860715047"},"user_tz":-120},"id":"pIZCYYiwMLUe","outputId":"537462b3-1f04-455d-c02a-55cb70af1dc3"},"outputs":[],"source":["confusion_matrix = pd.crosstab(data['true_label'], data['prediction'], rownames=['Target Class'], colnames=['Output Class'])\n","\n","sn.set(font_scale=1.1) # for label size\n","sn.heatmap(confusion_matrix, annot=True, fmt=\".0f\", annot_kws={\"size\": 13}, cmap='Blues')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}
